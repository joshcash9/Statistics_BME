---
title: \fontsize{18}{18}\selectfont\textcolor{myblue}{BMEG 802 -- Advanced Biomedical Experimental Design and Analysis}
subtitle: \fontsize{15}{15}\selectfont\textcolor{myblue}{One Way (Between) Analysis of Variance (ANOVA)}
author: \fontsize{12}{12}\selectfont\textcolor{gray}{Joshua G. A. Cashaback, PhD}
classoption: "aspectratio=169"
output: beamer_presentation
header-includes:
  - \usetheme[sectionpage = none]{metropolis}
  - \definecolor{myblue}{RGB}{11,184,253}
  - \definecolor{myorange}{RGB}{253,139,11}
  - \setbeamercolor{frametitle}{bg=white, fg=myblue}
  - \setbeamerfont{frametitle}{size=\LARGE,series=\bfseries}
  - \setbeamercolor{background canvas}{bg = white}
  #- \setbeamercolor{normal text}{fg=white}

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Recap

- Regression
  - Bivariate
    - Linear (Derivation)
    - Nonlinear
  - Multiple Regression

- Correlation
  - Pearson's r
  - Spearman's $\rho$
  
## 1 Way (Between) ANOVA

- develop logic & rationale for ANOVA (and formulas) based on a General Linear Model Approach
- any phenomenon is affected by multiple factors
- observed value on dependent variable (DV) = sum of effects of known factors + sum of effects of unknown factors
- similar idea to traditional approach of "accounting for variance" due to various factors
  - equivalent mathematically


## General Linear Model (GLM)

Let's develop a model that expresses dependent variable (DV) as a sum of known and unknown factors

$$DV = C + F + R$$

- C = constant factors (known)

- F = factors systematically varied (known) 

- R = randomly varying factors (unknown)

Notation looks like this:
$$Y_i = \beta_0 +\beta_1 \cdot X1_i + \beta_2 \cdot X2_i + \ldots + \beta_n \cdot Xn_i +\epsilon_i$$

## Single Group Example

- a little artificial (who ever does experiments using just one group?)
- but it will help us develop the ideas
- imagine we collect scores on some DV for a group of
subjects
- we want to compare the group mean to some known population mean
- e.g. IQ scores where by definition, $\mu = 100$ and $\sigma = 15$

## Single Group Example

We know that:

$H_0: \bar{Y} = \mu$

$H_1: \bar{Y} \neq \mu$

Let’s reformulate in terms of a GLM of the effects on DV:

\textcolor{myblue}{$H_0: \bar{Y} = \mu + \epsilon$}; where $\mu$ = 100

\textcolor{myorange}{$H_1: \bar{Y} = \hat{\mu} + \epsilon$}; where $\hat{\mu} = Y_i$

Terminology:

\textcolor{myblue}{$H_0$ is the "Restricted Model" --- no parameters need to be estimated}

\textcolor{myorange}{$H_0$ is the "Full Model" --- we need to estimate one parameter (can you see what it is?)}

## Computing Model Error

- how well do these two models fit our data?
- let’s use the \textbf{sum of squared deviations} of our model from
the data, as a measure of goodness of fit
$$H_0: \sum_{i=1}^{N}(e^2_i) = \sum_{i=1}^{N}(Y_i - 100)^2$$
$$H_1: \sum_{i=1}^{N}(e^2_i) = \sum_{i=1}^{N}(Y_i - \hat{\mu})^2 = \sum_{i=1}^{N}(Y_i - \hat{Y})^2$$
- SSE about the sample mean is lower than SSE about any other number
- so the error for $H_0$ \textcolor{myorange}{will} be greater than for $H_1$
- so the relevant question then is, \textcolor{myorange}{how much greater} must
$H_0$ error be,for us to reject $H_0$?

## Computing Model Error

- Consider the \textcolor{myblue}{Proportional Increase in Error (PIE)}
  - $(E_{restricted} - E_{full}) / E_{full}$
- PIE gives error increase for $H_0$ (restricted) compared to $H_1$ as (full) a % of $H_1$ error
- We want a model that is both
  - adequate (low error)
  - simple (few parameters to estimate)
- question: why do we want a simpler model?
  - philosophical reasons (Occam's razer)
  - statistical reasons (over-fitting)

## Computing Model Error

- how big is increase in error with $H_0$ (restricted model), \textcolor{myblue}{per unit of simplicity}?
- let’s design a test statistic that takes into account simplicity
- simplicity will be related to the number of parameters we have to estimate
- \textcolor{myblue}{degrees of freedom (df): \# of independent observations in the dataset minus \# of
independent parameters that need to be estimated}
- higher df = a simpler model

## Computing Model Error

Let’s normalize model errors (PIE) by model df
  - \textcolor{myorange}{This is called the F-statistic!}
$$F = \frac{(E_{restricted} - E_{full}) / (df_{restricted} - df_{full})}{(E_{full}/df_{full})}$$
We can compute $F_{obs}$ and calculate the probability of obtaining that F-statistic by using the F-distribution!

## Two Group Example

Let’s look at a more realistic situation

- 2 groups, 10 subjects in each group
  - test mean of group 1 vs mean of group 2
  - do we accept $H_0$ or $H_1$?
- we will formulate this question as before in terms of 2 linear models
  - full vs restricted model
  - is the error for the restricted model significantly higher
than for the full model?
  - is the decrease in error for the full model large enough
to justify the need to estimate a greater \# parameters?

## Two Group Example: Hypotheses and Models

\textcolor{myblue}{$H_0: \mu = \mu_1 = \mu_2$}

\textcolor{myblue}{restricted model: $Y_{ij} = \mu + \epsilon_{ij}$}

\textcolor{myorange}{$H_1: \mu_1 \neq \mu_2$}

\textcolor{myorange}{full model: $Y_{ij} = \mu_j + \epsilon_{ij}$}

i = individual (1, 2, ..., 10)

j = group (1 or 2)

Restricted model:
  
- each score $Y_{ij}$ is the result of a \textcolor{myblue}{single population mean} plus random error $\epsilon_{ij}$

Full model:

- each score $Y_{ij}$ is the result of a \textcolor{myorange}{ different group mean} plus random error $\epsilon_{ij}$

## Deciding between full and restricted model

- how do we decide between these two competing accounts of the data?

key question

- will a restricted model with fewer parameters be a significantly less adequate representation of the data than a full model with a parameter for each group?
- we have a trade-off between simplicity (fewer parameters) and adequacy (ability to accurately represent the data)

## Error for the Restricted Model

- Sum of squared deviations of each observation from the estimate of the population mean (given by the grand mean of all of the data)
- Here we need to estimate 1 parameter, $\hat{\mu}$

$$E_{restricted} = \sum_{j=1}^{n_j} \sum_{i = 1}^{n_i} (Y_{ij} - \hat{\mu})^2$$
$$\hat{\mu} = \frac{1}{n_i\cdot n_j}\sum_{j=1}^{n_j} \sum_{i = 1}^{n_i} (Y_{ij})$$

## Error for the Full Model

- Here we need to estimate 2 parameter (one for each group), $\hat{\mu_1}$ and $\hat{\mu_2}$

$$E_{full} = \sum_{j=1}^{n_j} \sum_{i = 1}^{n_i} (Y_{ij} - \hat{\mu_j})^2 = \sum_{i = 1}^{n_i} (Y_{i1} - \hat{\mu_1})^2 + \sum_{i = 1}^{n_i} (Y_{i2} - \hat{\mu_2})^2$$
$$\hat{\mu_1} = \frac{1}{n_1}\sum_{i = 1}^{n_i} (Y_{i1})$$
$$\hat{\mu_2} = \frac{1}{n_{2}}\sum_{i = 1}^{n_i} (Y_{i2})$$

## Deciding between Full and Restricted Model

Now we formulate our measure of proportional increase in error (PIE) as before using the F-statistic:
$$F = \frac{(E_{restricted} - E_{full}) / (df_{restricted} - df_{full})}{(E_{full}/df_{full})}$$

## Model Comparison Approach vs Traditional Approach to ANOVA

Traditional formulation of ANOVA asks the same question in a different way:

- is the variability \textcolor{myblue}{between groups (variance due to differences between groups)} greater than expected on the basis of the \textcolor{myblue}{within-group variability (the variability within a group)} observed, and random sampling of group members?

\textcolor{myorange}{Maxwell, Delaney, Kelley, Chapter 3: Proof that these two approaches are mathematically equivelant}

- both use sum of squares
- both use F-statistic

## Assumptions of the F test

1. the scores on the dependent variable Y are normally distributed in the population (and normally distributed within each group)
2. the population variances of scores on Y are equal for all groups
3. scores are independent of one another

## Violation of Assumption

- ANOVA is somewhat robust to violations of normality
- ANOVA is somewhat robust to homogeneity of variance
- ANOVA is NOT robust to violations of independence

## Three Group Example in R

- We can use ANOVA / GLM for 1 sample and 2 sample tests. 
  - But, equivalent to using a t-test
- ANOVA are most widely used when there is greater than 2 groups. - Acts as the "omnibus" test to decide whether you have "permission" to perform follow-up mean comparisons.

- Lets perform an ANOVA using R for the following simple example. We want to know if the following three groups are different from one another.

## Three Group Example in R

19 pigs are assigned at random amongst 4 experimental groups. Each group is fed a different diet. The data are pig body weights, in kg, after being raised on these diets. We wish to know if pig weights are the same for all diets.

\begin{center}
 \begin{tabular}{c | c | c} 
 Group 1 &  Group 2 &  Group 3 \\ [0.5ex] 
 \hline
 4 & 7 & 6 \\ 
 5 & 4 & 9 \\
 2 & 6 & 8 \\
1 & 3 & 5 \\
  3 & 5 & 7 \\
 \hline
 mean = 3 & mean = 5 & mean = 7 \\
\end{tabular}
\end{center}

\textcolor{myblue}{$H_0: \mu_1 = \mu_2 = \mu_3$}

\textcolor{myblue}{restricted model: $Y_{ij} = \mu + \epsilon_{ij}$}

\textcolor{myorange}{$H_1: \mu_1 \neq \mu_2 \neq \mu_3$}

\textcolor{myorange}{full model: $Y_{ij} = \mu_j + \epsilon_{ij}$}

## Three Group Example in R
Plot Restricted Model: Single parameter, $\mu$
\tiny
```{r, echo = TRUE, out.width="50%", fig.show="hold", fig.align="center"}
Y <- c(4,5,2,1,3,7,4,6,3,5,6,9,8,5,7)
myFac <- c(1,1,1,1,1,2,2,2,2,2,3,3,3,3,3) 
plot(Y, pch=myFac,main="restricted model") 
abline(h=mean(Y))
for (i in 1:length(Y)) {
  lines(c(i,i), c(Y[i], mean(Y)), lty=2)}
```

## Three Group Example in R
Plot Full Model: three parameters, $\mu_1, \mu_2, \mu_3$
\tiny
```{r, echo = TRUE, out.width="50%", fig.show="hold", fig.align="center"}
Y <- c(4,5,2,1,3,7,4,6,3,5,6,9,8,5,7) 
myFac <- c(1,1,1,1,1,2,2,2,2,2,3,3,3,3,3) 
plot(Y, pch=myFac, main="full model")
for (j in 1:3) {
  w <- which(myFac==j)  
  lines(c(min(w),max(w)),c(mean(Y[w]),mean(Y[w]))) 
  for (i in 1:length(w)) {
    lines(c(w[i],w[i]), c(Y[w[i]], mean(Y[w])), lty=2) }}
```

## Three Group Example in R

Using the aov() in R
```{r, echo = TRUE, out.width="50%", fig.show="hold", fig.align="center"}
m1 <- aov(Y ~ factor(myFac)) 
summary(m1)
```

\textcolor{myblue}{Here we find that there is statistically significant main effect of group (p = 0.006)!}

## Three Group Example in R

Alternatively we can build a linear model, using lm(), and then pass it through aov()
\tiny
```{r, echo = TRUE, out.width="50%", fig.show="hold", fig.align="center"}
m2 <- lm(Y ~ factor(myFac))
summary(m2)
```
\tiny
In this case the estimate for the first group (called Intercept in the anova output) is 3.0000. The estimate for the mean of group two is equal to the Intercept plus 2.0000, which equals 5.0000. Likewise the estimate for group three is 3.0000 + 4.0000 which equals 7.0000.

## Three Group Example in R

... now running an F-test on our linear model:
\tiny
```{r, echo = TRUE, out.width="50%", fig.show="hold", fig.align="center"}
anova(m2)
```
\small
The F-test of the main effect of the factor is called an omnibus test. A significant test indicates only that the population means are not equal
  —we would need to perform follow-up tests to find out specifically which groups differ. 

## Testing Normality
Use Shapiro-Wilk test on EACH group to test for normality (i.e., normal: p > 0.05). 
\tiny
```{r, echo = TRUE, out.width="50%", fig.show="hold", fig.align="center"}
shapiro.test(Y[1:5]) # group 1
shapiro.test(Y[5:10]) # group 2
shapiro.test(Y[11:15]) # group 3
```
\small
\textcolor{myblue}{There were no violations of Normality}


## Testing Homogeneity of Variances
\small
Bartlett test to test whether variances are similar (i.e., equal homogeneity of variance: p > 0.05)

\tiny
```{r, echo = TRUE, out.width="50%", fig.show="hold", fig.align="center"}
bartlett.test(Y ~ factor(myFac))
```

\small
\textcolor{myblue}{There is no violation of Homogeneity of Variances: p = 1.0}

- Data not normal? Can use transforms (e.g., log, square root, etc) OR a nonparametric version of the 1-way ANOVA, known as the Kruskal Wallis.

- Can perform Welch's corrections to F-test if variances are not equal using the oneway.test() OR use Kruskal Wallis.

## Follow up Mean Comparison's

\textcolor{myorange}{If ANOVA significant, as well as no violations of either normality or homogeneity of variance, you can perform follow-up mean compomparisons to test for differences between groups. Remember to correct for multiple comparisons!}
\small
```{r, echo = TRUE, out.width="50%", fig.show="hold", fig.align="center"}
pval_1v2 = t.test(Y[1:5], Y[5:10], alternative = "two.sided")$p.value # G1 vs G2
pval_1v3 = t.test(Y[1:5], Y[11:15], alternative = "two.sided")$p.value # G1 vs G3
pval_2v3 = t.test(Y[5:10], Y[11:15], alternative = "two.sided")$p.value # G2 vs G3
pvals = c(pval_1v2, pval_1v3, pval_2v3)
p.adjust(pvals, method = "holm", n = length(pvals))
```

\textcolor{myblue}{Interpretation: There is a significant main of effect of group (p = 0.006), where Group 3 is significantly greater than Group 1 (p = 0.012).}

## Graphing with GG Plot


## Next Week

- Factorial (2-way, 3-way, etc.) ANOVA
- Kruskal Wallis
  
  